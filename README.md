# ğŸ›ï¸ Customer Segmentation Using RFM and K-Means Clustering

## ğŸ“˜ Project Overview
This project applies **unsupervised learning** to segment retail customers based on purchasing behaviour.  
Using **Recency, Frequency, and Monetary (RFM)** metrics derived from transactional data, the goal is to help retailers understand and target customer groups more effectively â€” driving retention, loyalty, and sales growth.

---

## ğŸ¯ Problem Statement
Retailers often treat all customers the same, missing opportunities to tailor offers or engagement strategies.  
This project aims to identify **distinct customer groups** based on how recently, how often, and how much they purchase.  
By uncovering these segments, the business can:
- Reward loyal and high-value customers  
- Re-engage at-risk customers  
- Personalize marketing strategies  
- Optimize budget and improve ROI  

---

## ğŸ“‚ Dataset Information
**Dataset:** [Retail Sales Dataset â€“ Kaggle](https://www.kaggle.com/datasets/mohammadtalib786/retail-sales-dataset)

**Columns Used**
- `Customer ID` â€” unique identifier for each customer  
- `Order ID` â€” unique transaction identifier  
- `Order Date` â€” date of purchase  
- `Quantity` â€” number of items bought  
- `Unit Price` â€” price per item  
- `Amount` â€” total price per transaction  

**Why this dataset:**  
It contains key behavioural variables needed to compute RFM metrics and is clean, structured, and representative of a real retail business scenario.

---

## ğŸ§® Methodology

### 1ï¸âƒ£ Data Preparation
- Loaded and cleaned retail sales data.  
- Removed duplicates, negative quantities, and invalid entries.  
- Parsed order dates and ensured numerical consistency.

### 2ï¸âƒ£ Feature Engineering (RFM)
Computed three key customer metrics:
- **Recency** â†’ Days since last purchase  
- **Frequency** â†’ Number of unique orders  
- **Monetary** â†’ Total spending value  

3ï¸âƒ£ Data Transformation

Applied log transformation on Monetary to reduce skew.

Scaled RFM features using RobustScaler (less sensitive to outliers).

4ï¸âƒ£ Finding Optimal K

Tested cluster numbers (k = 2â€“8) using:

Elbow Method â†’ Finds the point where inertia reduction slows (the â€œelbowâ€).

Silhouette Score â†’ Measures how distinct and compact clusters are.

5ï¸âƒ£ Final Modelling

Applied K-Means with the best k (based on Silhouette).

Assigned each customer to a segment.

6ï¸âƒ£ Segment Profiling

Calculated averages per cluster:

Metric	Meaning	Desired Trend

Recency	Days since last purchase	Lower is better

Frequency	Number of orders	Higher is better

Monetary	Total spend: Higher is better


7ï¸âƒ£ Persona Labelling

Automatically ranked and labelled clusters:

ğŸ† Champions â€“ recent, frequent, high spenders

â¤ï¸ Loyal â€“ frequent buyers, moderate spenders

ğŸŒ± Promising â€“ newer or moderate buyers

âš ï¸ At Risk â€“ infrequent, havenâ€™t purchased recently

â„ï¸ Hibernating â€“ old, inactive customers

ğŸ“Š Key Insights

High-value â€œChampionsâ€ make up a small portion of customers but drive a large share of revenue.

â€œAt Riskâ€ and â€œHibernatingâ€ customers highlight opportunities for win-back campaigns.

Simple, data-driven segmentation enables targeted promotions and loyalty programs.

ğŸš€ Tools & Libraries

Python 3.10+

Pandas, NumPy â€” data wrangling

Matplotlib, Seaborn â€” visualisation

Scikit-learn â€” scaling, clustering, evaluation




ğŸ Results & Impact

Produced clear customer segments with interpretable patterns.

Provides actionable business insights for personalized marketing.

Demonstrates applied mastery of data cleaning, feature engineering, clustering, and model interpretation.

ğŸ‘¥ Author

Simeon Musa Nyakeh Vibbi
AI Saturdays Lagos â€” Machine Learning Flipped Cohort
ğŸ“§ svibbinyakeh@gmail.com
ğŸ”— [[Your LinkedIn ](https://www.linkedin.com/in/simeon-nyakeh-vibbi-a7992b178/)/ [GitHub Profile](https://github.com/SNVibbi)

ğŸ§¾ Acknowledgment

Special thanks to AI Saturdays Lagos mentors and peers for guidance throughout the ML Flipped Cohort.
Dataset credit: Mohammad Talib â€“ Kaggle
